---
title: "Politics Are Afoot!"
author: 'w203: Statistics for Data Science'
output: pdf_document
---

# The Setup 

There is *a lot* of money that is spent in politics in Presidential election years. Like, a lot, a lot. Estimates and analysis from the US Federal Election Comission, puts the total amount at about \$14,400,000,000 (\$14.4 billion USD). For context, Twitter's 2020 annual revenue was about \$3,500,000,000 ($3.5 billion USD). 

# The work 

Install the package, `fec16`. 

```{r}
## install.packages('fec16')
```

This package is a compendium  of spending and results from the 2016 election cycle. In this dataset are 9 different datasets that cover: 

- `candidates`: candidate attributes, like their name, a unique id of the candidate, the election year under consideration, the office they're running for, etc. 
- `results_house`: race attributes, like the name of the candidates running in the election, a unique id of the candidate, the number of `general_votes` garnered by each candidate, and other information. 
- `campaigns`: financial information for each house & senate campaign. This includes a unique candidate id, the total receipts (how much came in the doors), and total disbursements (the total spent by the campaign), the total contributed by party central committees, and other information. 

# Your task 

Your task is to describe the relationship between spending on a candidate's behalf and the votes they receive. 

If it is helpful to structure your response, you might want to place yourself into a scenario where you are advising a person or business about whether they should make a political donation. While the benefits that accrue as a result of a successful investment are unclear, you can be quite sure that investing with **no** return (i.e. more spending does not increase the chances of winning) is a bad idea.

# Your work 

- We want to keep this work *relatively* constrained, which is why we're providing you with data through the `fec16` package. It is possible to gather all the information from current FEC reports, but it would require you to make a series of API calls that would pull us away from the core modeling tasks that we want you to focus on instead. 
- Throughout this assignment, limit yourself to functions that are  within the `tidyverse` family of packages: `dplyr`, `ggplot`, `patchwork`, and `magrittr` for wrangling and exploration and `base`, `stats`, `sandwich` and `lmtest` for modeling and testing. You do not *have* to use these packages; but try to limit yourself to using only these. 
- Our choice to encourage you to use only these packages is to try to cut down on the amount of searching that you do: to help you avoid looking for the *"one package that does the thing I need it to do."* Certainly, such a package exists, but it will very likely be more productive for you to write things yourself than to try and find it for this homework. 

```{r load packages, echo=FALSE, message=FALSE}
library(tidyverse)
library(magrittr)
library(ggplot2)
library(patchwork)
library(sandwich)
library(lmtest)
library(fec16)
library(dbplyr)
```

```{r set themes, echo=FALSE}
theme_set(theme_minimal())
knitr::opts_chunk$set(dpi = 300)
```

```{r load data}
candidates    <- fec16::candidates
results_house <- fec16::results_house
campaigns     <- fec16::campaigns
```

## 1. What does the distribution of votes and of spending look like? 

1. (3 points) In separate histograms, show both the distribution of votes (measured in `results_house$general_percent` for now) and spending (measured in `ttl_disb`).  Use a log transform if appropriate for each visualization.  How would you describe what you see in these two plots?

```{r}
# explore the data

# plot the data
hist(results_house$general_percent, col = 'orange', breaks = 40, xlab = 'Percentages', main='Vote Percentages')
hist(log(campaigns$ttl_disb), col = 'purple', breaks = 40, xlab = 'Spend', main='Total Spend')

```

>
The original histogram of the results_house$general_percent is heavily skewed with a tail. The log histogram of the campaigns$ttl_disb is a standard normal distribution. 

## 2. Exploring the relationship between spending and votes. 

2. (3 points) Create a new dataframe by joining `results_house` and `campaigns` using the `inner_join` function from `dplyr`. (We use the format `package::function` -- so `dplyr::inner_join`.) Does this data frame contain all the data that was present in the two frames that you're joining together, or has some data been dropped? As you're manipulating data, keep a keen eye for what is, and what is not making it through your data $\to$ analysis $\to$ reporting pipeline. 

```{r join data frames}

df_inner_join <- inner_join(results_house, campaigns)

```

```{r evaluate the reults of that join}
# The dataframe results_house has 12 columns. The dataframe campaigns has 25 columns. 
```

> 
The inner join of the two dataframes does 
# contain all the columns with a total of 37 columns. The data does not match, as the original tables have 4008 rows but the join has 1342.

3. (3 points) Produce a scatter plot of `general_votes` on the y-axis and `ttl_disb` on the x-axis. What do you observe about the shape of the joint distribution? 

```{r}

ggplot(df_inner_join, aes(x = log10(ttl_disb), y =log10(general_votes) ) ) + 
  geom_point() + 
  ggtitle('Spend vs Votes') + 
  labs(x = 'Spend', y = 'Votes' ) + 
  geom_point(col='pink') + 
  geom_smooth(method = lm, se = FALSE) +
  geom_density2d(col = 'blue')


```

>
The log normalize the distribution. The data is heavly crowded to the right side. You can expect that an increase in the spend will increases the votes recieved. You can clearly see the density area in the right side. 

4. (3 points) Create a new variable to indicate whether each individual is a "Democrat", "Republican" or "Other Party". 
  - Here's an example of how you might use `mutate` and `case_when` together to create a variable. 

```{r}

df_inner_join <- df_inner_join %>%
  mutate(
    party_new = case_when(
      party == "REP" ~ "Republican",
      party == "DEM" ~ "Democrat", 
      TRUE           ~ "Other Party"
    )) 

```

Once you've produced the new variable, plot your scatter plot again, but this time adding an argument into the `aes()` function that colors the points by party membership.  What do you observe about the distribution of all three variables?

```{r party membership}

ggplot(df_inner_join, aes(x = log10(ttl_disb), y = log10(general_votes), color = party_new) ) +
  xlab("Total Spend") + 
  ylab("General Votes") +
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) +
  scale_color_manual(
    values = c("Republican" = "red",
               "Democrat" = "blue",
               "Other Party" = "green")
  )
  
  
```

>
The data is very crowded and sked to the left. What is now visable are the distinct political party clusters of the density distribution. 

# Produce a Descriptive Model 

For this section, rather than us providing you with `'fill in: '` prompts, you can write in whatever way is most effective for you. Please, limit this section to no more than three printed pages. (Your client -- aka the TAs -- have a finite attention span!)

5. (5 Points) Given your observations, produce a linear model that you think does a good job at describing the relationship between candidate spending and votes they receive. You should decide what transformation to apply to spending (if any), what transformation to apply to votes (if any) and also how to include the party affiliation.

6. (3 points) Evaluate the Large-Sample Linear Model Assumptions

7. (3 points) Interpret the model coefficients you estimate.

- Tasks to keep in mind as you're writing about your model: 
    - At the time that you're writing and interpreting your regression coefficients you'll be *deep* in the analysis. Nobody will know more about the data than you do, at that point. *So, although it will feel tedious, be descriptive and thorough in describing your observations.* 
    - It can be hard to strike the balance between: on the one hand,  writing enough of the technical underpinnings to know that your model meets the assumptions that it must; and, on the other hand, writing little enough about the model assumptions that the implications of the model can still be clear. We're starting this practice now, so that by the end of Lab 2 you will have had several chances to strike this balance.
```{r}

# wrangle data drop any NA and 0 from data
df_inner_join %>% drop_na(general_votes)
df_inner_join %>% drop_na(ttl_disb)
df_inner_join <- filter(df_inner_join, general_votes > 0, ttl_disb > 0)

# linear regression model on full data
model_1 <- lm(general_votes ~ ttl_disb, data = df_inner_join)
model_2 <- lm(log(general_votes) ~ log(ttl_disb), data = df_inner_join)
model_3 <- lm(log(general_votes) ~ ttl_disb, data = df_inner_join)
model_4 <- lm(log(general_votes) ~ log(ttl_disb) +  incumbent + factor(party_new), data = df_inner_join)

summary(model_1)
summary(model_2)
summary(model_3)
summary(model_4)

```
# Findings Analysis 



